{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LoanDSA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagHSAU_pngf"
      },
      "source": [
        "Lets load the required libraries for our analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rJJipCOphcg"
      },
      "source": [
        "#Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sySg9FeDpo0G"
      },
      "source": [
        "Lets load the loan applications training data set and assign it to a variable called \"iris\". We are using pandas to load the data. We will also use pandas next to explore the data both with descriptive statistics and data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZd38qItp6Xt"
      },
      "source": [
        "#Load dataset\n",
        "url = \"https://raw.githubusercontent.com/callxpert/datasets/master/Loan-applicant-details.csv\"\n",
        "names = ['Loan_ID','Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area','Loan_Status']\n",
        "dataset = pd.read_csv(url, names=names)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcJ2UUVEqCID"
      },
      "source": [
        "Lets take a peek at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCVuX2pjp_L2",
        "outputId": "3aa8f8e1-49c5-405a-9bea-f560d6427dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(dataset.head(20))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Loan_ID  Gender Married  ... Credit_History Property_Area Loan_Status\n",
            "0   LP001003    Male     Yes  ...              1         Rural           N\n",
            "1   LP001005    Male     Yes  ...              1         Urban           Y\n",
            "2   LP001006    Male     Yes  ...              1         Urban           Y\n",
            "3   LP001008    Male      No  ...              1         Urban           Y\n",
            "4   LP001011    Male     Yes  ...              1         Urban           Y\n",
            "5   LP001013    Male     Yes  ...              1         Urban           Y\n",
            "6   LP001014    Male     Yes  ...              0     Semiurban           N\n",
            "7   LP001018    Male     Yes  ...              1         Urban           Y\n",
            "8   LP001020    Male     Yes  ...              1     Semiurban           N\n",
            "9   LP001024    Male     Yes  ...              1         Urban           Y\n",
            "10  LP001028    Male     Yes  ...              1         Urban           Y\n",
            "11  LP001029    Male      No  ...              1         Rural           N\n",
            "12  LP001030    Male     Yes  ...              1         Urban           Y\n",
            "13  LP001032    Male      No  ...              1         Urban           Y\n",
            "14  LP001036  Female      No  ...              0         Urban           N\n",
            "15  LP001038    Male     Yes  ...              1         Rural           N\n",
            "16  LP001043    Male     Yes  ...              0         Urban           N\n",
            "17  LP001046    Male     Yes  ...              1         Urban           Y\n",
            "18  LP001047    Male     Yes  ...              0     Semiurban           N\n",
            "19  LP001066    Male     Yes  ...              1     Semiurban           Y\n",
            "\n",
            "[20 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDGGafmKqD1A"
      },
      "source": [
        "sklearn requires all inputs to be numeric, we should convert all our categorical variables into numeric by encoding the categories. This can be done using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS-8rxalqIPF"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']\n",
        "le = LabelEncoder()\n",
        "for i in var_mod:\n",
        "    dataset[i] = le.fit_transform(dataset[i])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCveL98JqLoM"
      },
      "source": [
        "#Splitting the Data set\n",
        "\n",
        "As we have seen already, In Machine learning we have two kinds of datasets\n",
        "\n",
        "    Training dataset - used to train our model\n",
        "    Testing dataset - used to test if our model is making accurate predictions\n",
        "\n",
        "Our dataset has 480 records. We are going to use 80% of it for training the model and 20% of the records to evaluate our model. copy paste the below commands to prepare our data sets\n",
        "\n",
        "Though our dataset has lot of columns, we are only going to use the Income fields, loan amount, loan duration and credit history fields to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2ib-hs6qQNY"
      },
      "source": [
        "array = dataset.values\n",
        "X = array[:,6:11]\n",
        "Y = array[:,12]\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=7)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzZpdEUgqTYZ"
      },
      "source": [
        "#Evaluating the model and training the Model\n",
        "\n",
        "We are going to apply the below four algorithms to this problem and evaluate its effectiveness. And finally choose the best algorithm and train it.\n",
        "\n",
        "    Logistic Regression : Logistic Regression is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables. To represent binary / categorical outcome, we use dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKjlPi0Zqfhg"
      },
      "source": [
        "#model = LogisticRegression()\n",
        "#model.fit(x_train, y_train)\n",
        "\n",
        "#predictions = model.predict(x_test)\n",
        "#print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2OXhNNEqizu"
      },
      "source": [
        "Decision tree : Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI-VMuKKqlWm",
        "outputId": "f3ed9fda-0abd-4397-e1b8-cc435a63bb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train,y_train)\n",
        "predictions = model.predict(x_test)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0257ab67aaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qldk5bOqnwu"
      },
      "source": [
        "Random forest : Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoU4HUhxqqru"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(x_train,y_train)\n",
        "predictions = model.predict(x_test)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaTqahUXqtvt"
      },
      "source": [
        "So, Regression algorithm works fine for our use case. We can change / play around with the variables that we used for training the model till we get better accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfcIjG19qy7h"
      },
      "source": [
        "We built an end-to-end project and tested different algorithms in this tutorial. This concludes this mini course on machine learning. Hope the course gave you a good primer to the machine learning concepts and boosted your overall confidence with machine learning."
      ]
    }
  ]
}